{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d7d5229",
   "metadata": {},
   "source": [
    "# Geometrical Methods in Machine Learning\n",
    "\n",
    "## Homework 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a565b733",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db98c34",
   "metadata": {},
   "source": [
    "### Task 1: Intrinsic dimension estimation (4 points)\n",
    "\n",
    "Implement $2$ intrinsic dimension estimation methods from a list below. Specify the methods you have chosen in the canvas Homework 2 comments.\n",
    "\n",
    "Each method should be realized as a Python class implementing public method `fit` as well as providing access to public class variable(s) `dimension` (all methods), `local_dimension`, `dimension_multiscale`, `local_dimension_multiscale` (specific methods).\n",
    "\n",
    "- `fit` method should return the estimate $\\hat{d}$ of the intrinsic dimensionality of the data as well as setting the scalar `dimension` property of the class,\n",
    "- if the method is _local_, the vector of dimension $n$ `local_dimension` property should be present with `dimension` being their median or mean aggregates along points,\n",
    "- if the method is _multiscale_, the vector of dimenson $s$ `dimension_multiscale` and the matrix of dimensions $s \\times n$ `local_dimension_multiscale` should be present as well, with `dimension` and `local_dimension` being their median or mean aggregates along scales.\n",
    "\n",
    "Be sure to give a method summary, describing its (see the examples below)\n",
    "- idea,\n",
    "- the estimator formula and/or algorithm,\n",
    "- the reference to pages with estimator derivation, and\n",
    "- the list of reference(s).\n",
    "\n",
    "**Grading:** Implementing any single method is awarded with $3$ points, implementing both with $4$ points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363e3236",
   "metadata": {},
   "source": [
    "### Intrinsic dimension estimation methods\n",
    "\n",
    "- [Levina2005] Levina, E., Bickel, P. Maximum Likelihood Estimation of Intrinsic Dimension. _Advances in Neural Information Processing Systems (2005)_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6073995c",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17573fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "X, y = load_digits(return_X_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b6ec99",
   "metadata": {},
   "source": [
    "#### MLE\n",
    "\n",
    "**Idea**\n",
    "\n",
    "Local intrinsic dimension estimator based on the principle of maximum likelihood to the distances between close neighbors.\n",
    "\n",
    "**Estimator formula/algorithm**\n",
    "\n",
    "Let we use $k$ nearest neighbors $\\mathbf{x}_1, \\dots, \\mathbf{k}_n$ of a point $\\mathbf{x}$ and $r_j = d(\\mathbf{x}, \\mathbf{x}_j)$ is the distance from a point $\\mathbf{x}$ to the $k$-th nearest neighbor, then the local MLE estimate of the intrinsic dimension is [Levina2005, Eq. 8]\n",
    "\n",
    "$$\\hat{d}_k(\\mathbf{x}) = \\left[ \\frac{1}{k - 1} \\sum_{j=1}^{k - 1} \\log \\frac{r_k(\\mathbf{x})}{r_j(\\mathbf{x})} \\right]^{-1}$$\n",
    "\n",
    "Averaging over $\\hat{d}_k(\\mathbf{x})$ gives the intrinsic dimension of the dataset $\\mathbf{X}$.\n",
    "\n",
    "**Estimator derivation**\n",
    "\n",
    "For derivation see [Levina2005, pp. 3-4].\n",
    "\n",
    "**References**  \n",
    "- [Levina2005] Levina, E., Bickel, P. Maximum Likelihood Estimation of Intrinsic Dimension. _Advances in Neural Information Processing Systems (2005)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6e1fd0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "class MLE():\n",
    "    \n",
    "    def __init__(self, k=5, aggregate=\"mean\", eps=1e-6):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.k = k\n",
    "        self.eps = eps\n",
    "        \n",
    "        if aggregate==\"mean\":\n",
    "            self.aggregate = np.mean\n",
    "        elif aggregate==\"median\":\n",
    "            self.aggregate = np.median\n",
    "        else:\n",
    "            raise ValueError(\"Aggregate function should be 'mean' or 'median'\")\n",
    "        \n",
    "    def fit(self, X):\n",
    "        \n",
    "        # get distances within up to the k-th nearest neighor for each point\n",
    "        nn = NearestNeighbors(n_neighbors=self.k).fit(X)\n",
    "        distances, _ = nn.kneighbors()\n",
    "        distances += self.eps # fix duplicate points, causing d(x_i, x_j)=0\n",
    "        \n",
    "        # get local and global intrinsic dimensions\n",
    "        log_distance_ratios = np.log(distances[:,self.k-1:self.k] / distances[:,:self.k-1])\n",
    "        self.local_dimension = ((self.k - 2) ** -1 * np.sum(log_distance_ratios, axis=1)) ** -1\n",
    "        self.dimension = self.aggregate(self.local_dimension)\n",
    "        \n",
    "        return self.dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "56011343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8.339146894870613, (1797,))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create estimator\n",
    "estimator = MLE()\n",
    "\n",
    "# fit estimator, returns (global) intrinsic dimension\n",
    "dimension = estimator.fit(X)\n",
    "\n",
    "# get estimates of global and local intrinsic dimensions\n",
    "dimension = estimator.dimension\n",
    "local_dimension = estimator.local_dimension\n",
    "\n",
    "dimension, local_dimension.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f49b8a",
   "metadata": {},
   "source": [
    "#### PCA-based\n",
    "\n",
    "**Idea**\n",
    "\n",
    "Global dimension estimator corresponding to specified level of explained variance given by the singular value decomposition of the centered data matrix.\n",
    "\n",
    "**References**  \n",
    "- [Pearson1901] Pearson, K. On Lines and Planes of Closest Fit to Systems of Points in Space. _Philosophical Magazine (1901)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b539adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "class PCAd():\n",
    "    \n",
    "    def __init__(self, explained_variance=0.95):\n",
    "        super().__init__()\n",
    "        self.explained_variance = explained_variance\n",
    "        \n",
    "    def fit(self, X):\n",
    "        pca = PCA(n_components=self.explained_variance)\n",
    "        pca.fit(X)\n",
    "        self.dimension = pca.n_components_\n",
    "\n",
    "        return self.dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db344239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create estimator\n",
    "estimator = PCAd()\n",
    "\n",
    "# fit estimator, returns (global) intrinsic dimension\n",
    "dimension = estimator.fit(X)\n",
    "\n",
    "# get estimate of (global) dimension\n",
    "dimension = estimator.dimension\n",
    "dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5576a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03143c2",
   "metadata": {},
   "source": [
    "### Task 2: Manifold learning (4 points)\n",
    "\n",
    "Obtain `Extended Yale B` face dataset ([download](https://github.com/oleg-kachan/GMML2023/blob/main/hw2/data/CroppedYale.zip)) which is comprised of $100 \\times 100$ pixels images of $38$ persons times $64$ illumination conditions. Resize images to $32 \\times 32$ pixels. You can do it using `Pillow` ([link](https://pillow.readthedocs.io/), tested) or any other image processing library of your choice.\n",
    "\n",
    "1. Estimate the intrinsic dimensionality with a method(s) of your choice (methods from task 1 are perfect candidates) and perform dimensionality reduction to the intrinsic dimension $\\hat{d}$ and dimensions $2$ or $3$ for visualization purposes using manifold learning methods of your choice.\n",
    "\n",
    "2. Compute NPR (neigborhood preservation ratio, see [seminar 4](https://github.com/oleg-kachan/GMML2022/blob/main/seminar4/seminar4_solution.ipynb)) of algorithms you have used for 2 different values of $d = \\{2$ or $3, \\hat{d} \\}$ and fixed number of nearest neighbors $k$. \n",
    "\n",
    "3. Explore the embedding space of dimension $2$ or $3$ for clusters and meaningful interpretations, comment the possible meaning of the new coordinates.\n",
    "\n",
    "4. Compute and plot persistence diagrams for dimensions $0$ and $1$, conclude whether the dataset have untrivial topology such a several clusters and/or presence of cycles in dimension $1$. If applicable, how can one explain a presence of cycles for the `Extended Yale B` face dataset?\n",
    "\n",
    "**Grading:** Each subtask is awarded with $1$ point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240aa6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23101d91",
   "metadata": {},
   "source": [
    "#### Grading:\n",
    "\n",
    "- 8/10 points are awarded for completing all the tasks and giving proper answers to questions.\n",
    "- 2/10 points are awarded for the quality of reporting, be sure to give explanations and comments to your solutions.\n",
    "- +1 extra point may be awarded for the extra work performed, be creative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
